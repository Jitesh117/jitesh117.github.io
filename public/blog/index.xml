<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jitesh117</title>
    <link>//localhost:1313/blog/</link>
    <description>Recent content on Jitesh117</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Apr 2024 11:56:07 +0530</lastBuildDate>
    <atom:link href="//localhost:1313/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Hierarchical Indexing in Pandas</title>
      <link>//localhost:1313/blog/hierarchical-indexing-in-pandas/</link>
      <pubDate>Thu, 25 Apr 2024 11:56:07 +0530</pubDate>
      <guid>//localhost:1313/blog/hierarchical-indexing-in-pandas/</guid>
      <description>Working with high-dimensional or categorized data can be a complex and challenging task, but Pandas provides a powerful tool to simplify this process: hierarchical indexing.
Hierarchical indexing, also known as multi-level or multi-indexed indexing, allows you to create and manipulate indexes with multiple levels or dimensions, providing a more intuitive and organized way to structure, access, and analyze your data.
This indexing technique is particularly useful when dealing with datasets that contain multiple levels of categorization or grouping, such as data from different regions, periods, or product categories.</description>
    </item>
    <item>
      <title>Activation Function and Loss Functions in Neural Networks</title>
      <link>//localhost:1313/blog/activation-function-and-loss-functions-in-neural-networks/</link>
      <pubDate>Fri, 19 Apr 2024 20:52:26 +0530</pubDate>
      <guid>//localhost:1313/blog/activation-function-and-loss-functions-in-neural-networks/</guid>
      <description>Activation Functions in Neural Networks Activation functions are a crucial component of artificial neural networks, serving as the mathematical operation that determines the output of a node or neuron. They introduce non-linearities to the network, allowing it to learn complex patterns and relationships within the data.
1. Sigmoid Function Sigmoid function, also known as the logistic function. This function squashes input values between 0 and 1, making it a popular choice for the output layer in binary classification problems.</description>
    </item>
    <item>
      <title>So You Think You Know Git?</title>
      <link>//localhost:1313/blog/so-you-think-you-know-git/</link>
      <pubDate>Mon, 15 Apr 2024 14:39:34 +0530</pubDate>
      <guid>//localhost:1313/blog/so-you-think-you-know-git/</guid>
      <description>This article is just about my learnings from the talk So you Think you know Git.
One might think that everything there is to know about Git has already been covered, but that would be wrong. Even today, the Git codebase is seeing around 9 commits per day and 10,000 commits in the last 3 years. That means there are still plenty of new things being added to Git that you might not know about.</description>
    </item>
    <item>
      <title>How I Learned to Type 150&#43; WPM</title>
      <link>//localhost:1313/blog/how-i-learned-to-type-fast/</link>
      <pubDate>Fri, 29 Mar 2024 16:25:00 +0530</pubDate>
      <guid>//localhost:1313/blog/how-i-learned-to-type-fast/</guid>
      <description>In this article I&amp;rsquo;m going to write about a topic very close to my heart, which is &amp;ldquo;How I Learned to type Faster&amp;rdquo;. Typing fast has been a game changer for me, and I believe anyone who types fast can become at least twice as productive as they already are.
But why bother to type fast? 1. It just really impresses people When people see me typing while coding, the single biggest compliment I&amp;rsquo;ve got is &amp;ldquo;Wow!</description>
    </item>
    <item>
      <title>Hash Tables Primer: The Ins and Outs of Efficient Key-Value Storage</title>
      <link>//localhost:1313/blog/the-ins-and-outs-of-hash-tables/</link>
      <pubDate>Tue, 26 Mar 2024 17:00:00 +0530</pubDate>
      <guid>//localhost:1313/blog/the-ins-and-outs-of-hash-tables/</guid>
      <description>Hash Tables are one of the most used Data structures, they&amp;rsquo;re so popular that almost every language has their own implementation and nomenclature of Hash Tables.
One very interesting fact about Hash Tables is that they&amp;rsquo;re also used as building blocks for:
Classes and its members Variable lookup table As we can see, Hash Tables are not just used in the business case of any application, but it&amp;rsquo;s also used in the inner working of any programming language.</description>
    </item>
    <item>
      <title>Why I use Vim and why you should too</title>
      <link>//localhost:1313/blog/why-i-use-vim-and-why-you-should-too/</link>
      <pubDate>Wed, 20 Mar 2024 07:00:00 +0530</pubDate>
      <guid>//localhost:1313/blog/why-i-use-vim-and-why-you-should-too/</guid>
      <description>VIM or Vi Improved, is a free and open-source text editor for the terminal written by Bram Moolenaar. It is a highly powerful and versatile text editor that has managed to gather a devoted following among many people. Known for its efficiency, speed, and extensive customization options, Vim offers a unique modal editing approach that distinguishes it from traditional text editors.
Although I was familiar with Vim since 2020, I never thought of actually using it.</description>
    </item>
    <item>
      <title>Hyperparameter Tuning and Ensembling</title>
      <link>//localhost:1313/blog/ensembling-and-hyperparameter-tuning/</link>
      <pubDate>Sat, 16 Mar 2024 17:56:43 +0530</pubDate>
      <guid>//localhost:1313/blog/ensembling-and-hyperparameter-tuning/</guid>
      <description>Ensembling, a powerful technique in machine learning, has gained widespread popularity for its ability to significantly enhance predictive performance. By combining the predictions of multiple individual models, ensembles can often achieve better results than any single model alone. However, to fully leverage the potential of ensembling, it&amp;rsquo;s crucial to fine-tune the hyperparameters of the underlying base models.
Hyperparameter tuning involves searching for the optimal combination of model parameters that maximizes performance metrics such as accuracy or F1 score.</description>
    </item>
  </channel>
</rss>
