<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jitesh117</title>
    <link>//localhost:1313/</link>
    <description>Recent content on Jitesh117</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Apr 2024 20:52:26 +0530</lastBuildDate>
    <atom:link href="//localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Activation Function and Loss Functions in Neural Networks</title>
      <link>//localhost:1313/blog/activation-function-and-loss-functions-in-neural-networks/</link>
      <pubDate>Fri, 19 Apr 2024 20:52:26 +0530</pubDate>
      <guid>//localhost:1313/blog/activation-function-and-loss-functions-in-neural-networks/</guid>
      <description>Activation Functions in Neural Networks Activation functions are a crucial component of artificial neural networks, serving as the mathematical operation that determines the output of a node or neuron. They introduce non-linearities to the network, allowing it to learn complex patterns and relationships within the data.
1. Sigmoid Function Sigmoid function, also known as the logistic function. This function squashes input values between 0 and 1, making it a popular choice for the output layer in binary classification problems.</description>
    </item>
    <item>
      <title>So You Think You Know Git?</title>
      <link>//localhost:1313/blog/so-you-think-you-know-git/</link>
      <pubDate>Mon, 15 Apr 2024 14:39:34 +0530</pubDate>
      <guid>//localhost:1313/blog/so-you-think-you-know-git/</guid>
      <description>This article is just about my learnings from the talk So you Think you know Git.
One might think that everything there is to know about Git has already been covered, but that would be wrong. Even today, the Git codebase is seeing around 9 commits per day and 10,000 commits in the last 3 years. That means there are still plenty of new things being added to Git that you might not know about.</description>
    </item>
    <item>
      <title>The Trap of Knowing What You Want</title>
      <link>//localhost:1313/musings/the-trap-of-knowing-what-you-want/</link>
      <pubDate>Wed, 10 Apr 2024 14:27:45 +0530</pubDate>
      <guid>//localhost:1313/musings/the-trap-of-knowing-what-you-want/</guid>
      <description>In our world, we often think that finding our passion and purpose is the key to being happy. But this can actually be a trap. Many people think they know what they want, and they chase after those things, believing they will finally feel satisfied. But then they end up feeling lost and unfulfilled anyway.
Having a clear idea of what you desire can be powerful. But we have to be careful, because this mindset also has its limits.</description>
    </item>
    <item>
      <title>Making and Losing Friends</title>
      <link>//localhost:1313/musings/making-and-losing-friends-in-life/</link>
      <pubDate>Sat, 06 Apr 2024 15:47:15 +0530</pubDate>
      <guid>//localhost:1313/musings/making-and-losing-friends-in-life/</guid>
      <description>Friends are the one thing which can change the outlook of anything which is happening in our lives. Having their mere presence can amplify any happiness.
Growing up as a kid whose father worked in the Indian Air Force, I had to switch cities a lot. While it meant I got to make new friends every 3-5 years, it also meant losing most of my friends whenever I changed places. Each new transfer meant saying goodbye to old friends and diving into a new adventure.</description>
    </item>
    <item>
      <title>Papers</title>
      <link>//localhost:1313/shelf/papers/</link>
      <pubDate>Sun, 31 Mar 2024 16:20:40 +0530</pubDate>
      <guid>//localhost:1313/shelf/papers/</guid>
      <description> Attention is all you need Pre-train, Prompt and Recommendation: A Comprehensive Survey of Language Modelling Paradigm Adaptations in Recommender Systems </description>
    </item>
    <item>
      <title>Articles</title>
      <link>//localhost:1313/shelf/articles/</link>
      <pubDate>Sun, 31 Mar 2024 16:20:20 +0530</pubDate>
      <guid>//localhost:1313/shelf/articles/</guid>
      <description> Being a Noob by Paul Graham My GitHub Project went viral by Aditya Lenge How to keep yourself unblocked by Arpit Bhayani </description>
    </item>
    <item>
      <title>Books</title>
      <link>//localhost:1313/shelf/books/</link>
      <pubDate>Sun, 31 Mar 2024 16:20:09 +0530</pubDate>
      <guid>//localhost:1313/shelf/books/</guid>
      <description>Fiction 1984 by George Orwell By the River Piedra I sat down and wept by Paulo Coelho Animal Farm By George Orwell Halo The Forerunner Saga series by Greg bear Non-fiction Show Your Work by Austin Kleon The Art of War by Sun Tzu The Psychology of Money by Morgan Housel Fooled by Randomness by Nassim Nicholas Taleb </description>
    </item>
    <item>
      <title>How I Learned to Type 150&#43; WPM</title>
      <link>//localhost:1313/blog/how-i-learned-to-type-fast/</link>
      <pubDate>Fri, 29 Mar 2024 16:25:00 +0530</pubDate>
      <guid>//localhost:1313/blog/how-i-learned-to-type-fast/</guid>
      <description>In this article I&amp;rsquo;m going to write about a topic very close to my heart, which is &amp;ldquo;How I Learned to type Faster&amp;rdquo;. Typing fast has been a game changer for me, and I believe anyone who types fast can become at least twice as productive as they already are.
But why bother to type fast? 1. It just really impresses people When people see me typing while coding, the single biggest compliment I&amp;rsquo;ve got is &amp;ldquo;Wow!</description>
    </item>
    <item>
      <title>Hash Tables Primer: The Ins and Outs of Efficient Key-Value Storage</title>
      <link>//localhost:1313/blog/the-ins-and-outs-of-hash-tables/</link>
      <pubDate>Tue, 26 Mar 2024 17:00:00 +0530</pubDate>
      <guid>//localhost:1313/blog/the-ins-and-outs-of-hash-tables/</guid>
      <description>Hash Tables are one of the most used Data structures, they&amp;rsquo;re so popular that almost every language has their own implementation and nomenclature of Hash Tables.
One very interesting fact about Hash Tables is that they&amp;rsquo;re also used as building blocks for:
Classes and its members Variable lookup table As we can see, Hash Tables are not just used in the business case of any application, but it&amp;rsquo;s also used in the inner working of any programming language.</description>
    </item>
    <item>
      <title>Why I use Vim and why you should too</title>
      <link>//localhost:1313/blog/why-i-use-vim-and-why-you-should-too/</link>
      <pubDate>Wed, 20 Mar 2024 07:00:00 +0530</pubDate>
      <guid>//localhost:1313/blog/why-i-use-vim-and-why-you-should-too/</guid>
      <description>VIM or Vi Improved, is a free and open-source text editor for the terminal written by Bram Moolenaar. It is a highly powerful and versatile text editor that has managed to gather a devoted following among many people. Known for its efficiency, speed, and extensive customization options, Vim offers a unique modal editing approach that distinguishes it from traditional text editors.
Although I was familiar with Vim since 2020, I never thought of actually using it.</description>
    </item>
    <item>
      <title>Hyperparameter Tuning and Ensembling</title>
      <link>//localhost:1313/blog/ensembling-and-hyperparameter-tuning/</link>
      <pubDate>Sat, 16 Mar 2024 17:56:43 +0530</pubDate>
      <guid>//localhost:1313/blog/ensembling-and-hyperparameter-tuning/</guid>
      <description>Ensembling, a powerful technique in machine learning, has gained widespread popularity for its ability to significantly enhance predictive performance. By combining the predictions of multiple individual models, ensembles can often achieve better results than any single model alone. However, to fully leverage the potential of ensembling, it&amp;rsquo;s crucial to fine-tune the hyperparameters of the underlying base models.
Hyperparameter tuning involves searching for the optimal combination of model parameters that maximizes performance metrics such as accuracy or F1 score.</description>
    </item>
  </channel>
</rss>
